# ğŸ§  Multi-Agent LLM Chat with LangGraph + Streamlit

This project is a modular, scalable multi-agent system built using **LangGraph**, **Streamlit**, and **LangChain**, supporting both **OpenAI** and **Google Gemini** LLMs. It dynamically routes user queries to the most appropriate agent based on message content.

---

## ğŸ“¦ Features

- âœ… Modular Agent Handlers 
- ğŸ” Dynamic Agent Routing via LLM
- ğŸ§  Support for OpenAI and Gemini (switchable)
- ğŸ’¬ Streamlit Chat Interface
- ğŸ” Unit Test Coverage

---

```
multi_agent_project/
â”œâ”€â”€ agents/               # Individual agent logic (e.g. agent_1.py ... agent_10.py)
â”œâ”€â”€ utils/                # LLM switch, router logic
â”œâ”€â”€ workflows/            # LangGraph builder
â”œâ”€â”€ tests/                # Unit tests
â”œâ”€â”€ .env                  # Environment variables
â”œâ”€â”€ app.py                # Streamlit app
â”œâ”€â”€ requirements.txt      # Dependencies
â””â”€â”€ README.md
```

### 1. Create Virtual Environment
```bash
python -m venv venv
.\venv\Scripts\activate  # or venv\Scripts\activate on Windows

```

### 2. Set Environment Variables
Create a `.env` file:
```env
LLM_PROVIDER=openai           # or gemini
OPENAI_API_KEY=your-openai-key
GEMINI_API_KEY=your-gemini-key
```

### 3. Install Dependencies
```bash
pip install -r requirements.txt
```

### 4. Run the Streamlit App
```bash
streamlit run ui/app.py
```
### 5. Run the Streamlit App
```bash
uvicorn services.api:app --reload
```

LLM_PROVIDER=gemini

# OpenAI config
OPENAI_API_KEY=Your Key
OPENAI_MODEL=gpt-3.5-turbo

# Gemini config
GEMINI_API_KEY=Your Key
GEMINI_MODEL=models/gemini-2.0-flash-thinking-exp